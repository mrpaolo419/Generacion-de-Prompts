{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrpaolo419/Generacion-de-Prompts/blob/main/proyecto_de_nutricion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_dvtXXS66gJQ",
        "outputId": "6fcd3ed2-c614-421c-f978-f6326d6368d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.10.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "Successfully installed openai-0.28.0\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U -q google-generativeai\n",
        "!pip install openai==0.28\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5DBUJjj1Tq0q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "T1M1kxOX62OP"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import openai\n",
        "import requests\n",
        "import os\n",
        "from io import BytesIO\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PBHg19wnw7lT"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QM8_vf9q9Scr"
      },
      "outputs": [],
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('Generative-Language-Client')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-tQkQIjyBa-G"
      },
      "outputs": [],
      "source": [
        "# Create the model\n",
        "generation_config = {\n",
        "  \"temperature\": 1,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 64,\n",
        "  \"max_output_tokens\": 500,\n",
        "  \"response_mime_type\": \"text/plain\",\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-flash\",\n",
        "  generation_config=generation_config,\n",
        "  # safety_settings = Adjust safety settings\n",
        "  # See https://ai.google.dev/gemini-api/docs/safety-settings\n",
        "  system_instruction = \"Hola, soy Yanina, la nutricionista del hospital. Estoy aquÃ­ para brindarte consejos personalizados sobre nutriciÃ³n y ayudarte a mejorar tu salud a travÃ©s de una alimentaciÃ³n adecuada. Mi enfoque es exclusivamente en temas de nutriciÃ³n, asÃ­ que si tienes alguna duda o necesitas orientaciÃ³n en este Ã¡mbito, estarÃ© encantada de ayudarte.\",\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rFFeH1A-Icmd"
      },
      "outputs": [],
      "source": [
        "history_chat = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "n2UMuVf6GadS"
      },
      "outputs": [],
      "source": [
        "historial = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LG43AG_mBgH1"
      },
      "outputs": [],
      "source": [
        "def chat():\n",
        "    chat_session = model.start_chat(history=history_chat)\n",
        "\n",
        "    print(\"Soy Yanina, la nutricionista. PÃ­deme consejos de nutriciÃ³n. Escribe 'salir' para terminar.\")\n",
        "\n",
        "    while True:\n",
        "        user_message = input(\"TÃº: \")\n",
        "\n",
        "        if user_message.lower() == \"salir\":\n",
        "            break\n",
        "\n",
        "        response = chat_session.send_message(user_message)\n",
        "        print(\"Yanina:\", response.text)\n",
        "\n",
        "        history_chat.append({'role': 'user', 'parts': [user_message]})\n",
        "        history_chat.append({'role': 'model', 'parts': [response.text]})\n",
        "\n",
        "        if len(history_chat) == 3:\n",
        "            generate_image = input(\"Â¿Generar una imagen? (sÃ­/no): \").strip().lower()\n",
        "\n",
        "            if generate_image == \"si\" or generate_image == \"si\":\n",
        "                image_url = generate_image_with_openai(user_message)\n",
        "\n",
        "                print(f\"image_url: {image_url}\")\n",
        "                history_chat.append({'role': 'model', 'parts': [f\"URL de la imagen: {image_url}\"]})\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Y8fS7Irzv3nv"
      },
      "outputs": [],
      "source": [
        "def generate_image_with_openai(prompt):\n",
        "\n",
        "    image_response = openai.Image.create(\n",
        "        prompt=prompt,\n",
        "        n=1,\n",
        "        size=\"1024x1024\"\n",
        "    )\n",
        "\n",
        "\n",
        "    response = image_response['data'][0]['url']\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwSYVhsZwEWw",
        "outputId": "69a80890-8383-46c5-b039-825cd3eb1de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error al generar la imagen: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\n"
          ]
        }
      ],
      "source": [
        "def generate_image_with_openai(prompt):\n",
        "    try:\n",
        "        response = openai.Image.create(prompt=prompt, n=1, size=\"1024x1024\")\n",
        "        return response['data'][0]['url']\n",
        "    except Exception as e:\n",
        "        print(f\"Error al generar la imagen: {e}\")\n",
        "        return None\n",
        "\n",
        "def save_and_display_image(image_url, prompt):\n",
        "    try:\n",
        "        response = requests.get(image_url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            filename = os.path.basename(image_url).split('.')[0] + \".png\"\n",
        "            directory = \"./generated_images/\"\n",
        "\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "\n",
        "            filepath = os.path.join(directory, filename)\n",
        "\n",
        "            with open(filepath, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "\n",
        "            print(\"La imagen ha sido descargada y almacenada correctamente en:\", filepath)\n",
        "\n",
        "            img = Image.open(filepath)\n",
        "            img.show()\n",
        "            print(f\"Prompt utilizado: {prompt}\")\n",
        "\n",
        "        else:\n",
        "            print(\"Hubo un error al descargar la imagen.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al guardar o mostrar la imagen: {e}\")\n",
        "\n",
        "response_of_function_gemini = \"Tu prompt aquÃ­\"\n",
        "image_url = generate_image_with_openai(response_of_function_gemini)\n",
        "\n",
        "if image_url:\n",
        "    save_and_display_image(image_url, response_of_function_gemini)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "7QibOm-RIgjV",
        "outputId": "8160b49c-e094-4f28-dc86-3ed299ed8128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soy Yanina, la nutricionista. PÃ­deme consejos de nutriciÃ³n. Escribe 'salir' para terminar.\n",
            "TÃº: hola\n",
            "Yanina: Â¡Hola! ğŸ‘‹ Â¿QuÃ© te trae por aquÃ­ hoy? ğŸ˜Š Â¿Tienes alguna duda o necesitas alguna recomendaciÃ³n sobre nutriciÃ³n? Estoy aquÃ­ para ayudarte a mejorar tu salud a travÃ©s de la alimentaciÃ³n. \n",
            "\n",
            "TÃº: salir\n"
          ]
        }
      ],
      "source": [
        "chat()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUOauiNnph6kPJPpuwh7fz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}